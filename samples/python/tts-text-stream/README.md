# Examples to synthesis with input text stream

The input text stream API is designed to generate audio from text that is being streamed or generated in chunks. A typical scenario is to speak text generated from GPT-like models. Compared to non-text stream APIs, the text stream API significantly reduces TTS latency.

|  | Non text stream | Text Stream |
| ---------- | -------- | ----------- |
| Input Type | Whole GPT response | Each GPT output chunk |
| Latency | High: Time of full GPT response + Time of TTS | Low: Time of few GPT chunks + Time of TTS |

### Available samples:

| Language | Directory | Description |
| ---------- | -------- | ----------- |
| Python | [python](text_stream_sample.py) | synthesis with text stream API, the text stream generated by AOAI GPT chat model  |

## API overview
### Create text stream request
To use the text stream API, you have to use the websocket V2 endpoint.  
```wss://{region}.tts.speech.microsoft.com/cognitiveservices/websocket/v2```

### Set global properties
Since the input of text stream API is parital text. SSML, which is based on XML, is not supported. And thus properties that set in SSML should be set in a new way.  

For now we only support set voice name and output format.

### Create input text stream
Please specify `speechsdk.SpeechSynthesisRequestInputType.TextStream` when creating the request.

### Send text to stream
For each text that generated from GPT, call `request.input_stream.write(text)` to send text to the stream.

### Close text stream
When GPT finished the output, call `request.input_stream.close()` to close the stream.

